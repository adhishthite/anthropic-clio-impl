# CLIO pipeline default configuration
# API keys are loaded from .env - do not put secrets here.

openai_model: "gpt-4.1-mini"
openai_temperature: 0.0
openai_max_concurrency: 8
openai_input_cost_per_1m_tokens: null
openai_output_cost_per_1m_tokens: null
stream_chunk_size: 200
client_max_retries: 4
client_backoff_seconds: 1.0
embedding_provider: "jina"
embedding_model: "jina-embeddings-v3"

k_base_clusters: 20
clustering_strategy: "hybrid"
clustering_leaf_mode: "auto"
clustering_target_leaf_size: 25
clustering_min_leaf_clusters: 20
clustering_max_leaf_clusters: 600
clustering_hdbscan_min_cluster_size: 12
clustering_hdbscan_min_samples: 6
clustering_noise_policy: "nearest"
embedding_batch_size: 32
facet_batch_size: 8
facet_max_concurrency: 8
cluster_label_sample_size: 12
cluster_label_max_concurrency: 8
hierarchy_top_k: 10
hierarchy_levels: 3
hierarchy_depth_policy: "adaptive"
hierarchy_target_group_size: 8
hierarchy_label_max_concurrency: 8
viz_projection_method: "umap"
random_seed: 42

min_unique_users: 5
min_conversations_per_cluster: 10
privacy_threshold_min_rating: 3
privacy_audit_raw_sample_size: 40
privacy_batch_size: 12
privacy_max_concurrency: 8
privacy_validation_enabled: true

eval_synthetic_count: 120
eval_topic_count: 8
eval_language_count: 5
eval_seed: 19

input_conversations_path: "data/mock/conversations_llm_200.jsonl"
data_dir: "data"
output_dir: "runs"
